# [[Recommended Reading List]]
# [[Further Reading Resources]]

This note contains a list of resources for further reading, categorized for easier access.

**I.  Mathematics & Statistics:**

* **Linear Algebra:**
    * [[Linear Algebra Review]]  (This will cover eigenvalues, eigenvectors, matrix decompositions etc.)
    * Book: *Linear Algebra and Its Applications* by David C. Lay
* **Probability & Statistics:**
    * [[Probability Distributions]] (This will cover normal, binomial, Poisson distributions etc.)
    * [[Statistical Inference]] (Hypothesis testing, confidence intervals etc.)
    * Book: *Introduction to Statistical Learning* by Gareth James et al.
* **Calculus:**
    * [[Calculus Fundamentals]] (Limits, derivatives, [[integrals]])
    * Book: *Calculus* by James Stewart


**II.  Computer Science & Programming:**

* **Python:**
    * [[Python Libraries for Data Science]] (NumPy, Pandas, Scikit-learn)
    * Online Course:  DataCamp's Python for Data Science track
* **Machine Learning:**
    * [[Supervised Learning Algorithms]] (Linear Regression, Logistic Regression, SVM, Decision Trees)
    * [[Unsupervised Learning Algorithms]] (Clustering, Dimensionality Reduction)
    * Book: *Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow* by Aurélien Géron
* **Deep Learning:**
    * [[Deep Learning Architectures]] (CNNs, RNNs, Transformers)
    * [[Backpropagation]] (This note will cover backpropagation algorithm in detail)
    * Online Course:  fast.ai's deep learning course


**III.  Specific Applications:**

* **Natural [[Language]] Processing (NLP):**
    * [[NLP Techniques]] (Tokenization, stemming, lemmatization, word embeddings)
    * [[NLP Models]] (Transformers, Recurrent Neural Networks)
* **Computer Vision:**
    * [[Image Processing Techniques]] (Image filtering, edge detection, feature extraction)
    * [[Convolutional Neural Networks (CNNs)]]

**IV.  Research Papers:**

* Keep a running list of relevant papers using a citation manager like Zotero or Mendeley.  This will require a separate [[Citation Management System Setup]] note.


**Useful Equations:**

* **Mean:** $ \mu = \frac{[[1}{N} \sum_{i=[[1}^{N} x_i $
* **Variance:** $ \sigma^2 = \frac{[[1}{N} \sum_{i=[[1}^{N} (x_i - \mu)^2 $
* **Standard Deviation:** $ \sigma = \sqrt{\sigma^2} $


**V. Websites and Blogs:**

*  Towards Data Science
*  Arxiv
*  Google Scholar



This structure allows for easy expansion and linking between related topics.  Remember to fill in the linked notes as needed.
